{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1467a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up logging for notebook output\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa11cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract YouTube videoID\n",
    "import re\n",
    "\n",
    "def extract_youtube_video_id(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the videoID from a YouTube URL.\n",
    "    Supports standard and shortened YoutTube URL\n",
    "    \"\"\"\n",
    "\n",
    "    # Standard YouTube URL\n",
    "    match = re.search(r\"(?:v=|\\/)([0-9A-Za-z_-]{11})\", url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    raise ValueError(\"Invalid YouTube URL format\")\n",
    "\n",
    "# test:\n",
    "# youtube_url = \"https://www.youtube.com/watch?v=KgVu9G-VcQk&pp=ygUPMzAgbWlucyBwb2RjYXN0\" # joe rogan\n",
    "# video_id = extract_youtube_video_id(youtube_url)\n",
    "# video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5ac26ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download audio from YouTube\n",
    "import subprocess\n",
    "\n",
    "def download_youtube_audio(video_id: str, output_dir: str = \"audio\") -> Path:\n",
    "    \"\"\"\n",
    "    Downloads the audio from a YouTube video using yt-dlp.\n",
    "    Returns the path to the downloaded audio file.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    output_path = Path(output_dir) / f\"{video_id}.m4a\"\n",
    "    youtube_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "    command = [\n",
    "        \"yt-dlp\",\n",
    "        \"-f\", \"bestaudio[ext=m4a]\",\n",
    "        \"-o\", str(output_path),\n",
    "        youtube_url\n",
    "    ]\n",
    "\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(f\"yt-dlp failed: {result.stderr}\")\n",
    "    return output_path\n",
    "\n",
    "# test\n",
    "# audio_path = download_youtube_audio(video_id)\n",
    "# print(f\"Audio downloaded to: {audio_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cba4b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import assemblyai as aai\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Transcribe and optionally return the full transcript object\n",
    "def transcribe_with_assemblyai(audio_file_path: str, api_key: str = None, return_transcript: bool = False):\n",
    "    \"\"\"\n",
    "    Transcribes `audio_file_path` with AssemblyAI.\n",
    "    If `return_transcript` is True, returns the full transcript object;\n",
    "    otherwise returns transcript.words.\n",
    "    \"\"\"\n",
    "    if api_key is None:\n",
    "        load_dotenv()\n",
    "        api_key = os.getenv(\"ASSEMBLYAI_API_KEY\")\n",
    "    aai.settings.api_key = api_key\n",
    "\n",
    "    config = aai.TranscriptionConfig(\n",
    "        speech_model=aai.SpeechModel.best,\n",
    "        speaker_labels=True,\n",
    "        speakers_expected=2,\n",
    "    )\n",
    "    transcript = aai.Transcriber(config=config).transcribe(audio_file_path)\n",
    "\n",
    "    if transcript.status == \"error\":\n",
    "        raise RuntimeError(f\"Transcription failed: {transcript.error}\")\n",
    "    return transcript if return_transcript else transcript.words\n",
    "\n",
    "# test:\n",
    "# transcript = transcribe_with_assemblyai(f\"audio/{video_id}.m4a\", return_transcript=True)\n",
    "# transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c362f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save word-level transcript to JSON\n",
    "import json\n",
    "\n",
    "def save_word_level_transcript(obj, output_path: str):\n",
    "    \"\"\"\n",
    "    Accepts either transcript.words or the full transcript object.\n",
    "    Saves word-level data to JSON.\n",
    "    \"\"\"\n",
    "    # If a full transcript is passed, use its .words attribute\n",
    "    words = obj.words if hasattr(obj, \"words\") else obj\n",
    "\n",
    "    word_data = []\n",
    "    for idx, word in enumerate(words):\n",
    "        word_data.append({\n",
    "            \"id\": idx + 1,\n",
    "            \"text\": word.text,\n",
    "            \"start\": word.start,\n",
    "            \"end\": word.end,\n",
    "            \"confidence\": word.confidence,\n",
    "            \"speaker\": word.speaker\n",
    "        })\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(word_data, f, indent=2)\n",
    "    print(f\"Saved word-level transcript to {output_path}\")\n",
    "\n",
    "# test:\n",
    "# save_word_level_transcript(transcript.words, \"transcript.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d03081d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping words into thought segments\n",
    "from typing import List, Dict, Optional\n",
    "from datetime import timedelta\n",
    "import re\n",
    "\n",
    "def group_words_into_thoughts(word_data, pause_threshold_ms=3000):\n",
    "    \"\"\"\n",
    "    Groups words (AssemblyAI Word objects) into thoughts based on speaker changes and pauses.\n",
    "    Adds word_start and word_end (1-based indices in the original word_data).\n",
    "    \"\"\"\n",
    "    thoughts = []\n",
    "    current_thought = []\n",
    "    word_indices = []  # Track the original indices of words in each thought\n",
    "\n",
    "    for i, word in enumerate(word_data):\n",
    "        if current_thought and (\n",
    "            current_thought[-1].speaker != word.speaker or\n",
    "            word.start - current_thought[-1].end > pause_threshold_ms\n",
    "        ):\n",
    "            thoughts.append((current_thought, word_indices))\n",
    "            current_thought = []\n",
    "            word_indices = []\n",
    "        current_thought.append(word)\n",
    "        word_indices.append(i)\n",
    "    if current_thought:\n",
    "        thoughts.append((current_thought, word_indices))\n",
    "\n",
    "    # Build thought dicts with word_start and word_end\n",
    "    thought_dicts = []\n",
    "    for idx, (words, indices) in enumerate(thoughts):\n",
    "        text = ' '.join(w.text for w in words)\n",
    "        start = words[0].start\n",
    "        end = words[-1].end\n",
    "        duration = end - start\n",
    "        avg_conf = sum(w.confidence * (w.end - w.start) for w in words) / max(1, sum(w.end - w.start for w in words))\n",
    "        word_start = indices[0] + 1  # 1-based index\n",
    "        word_end = indices[-1] + 1   # 1-based index\n",
    "        thought_dicts.append({\n",
    "            'id': f\"t_{idx+1:04d}\",\n",
    "            'speaker': words[0].speaker,\n",
    "            'text': text,\n",
    "            'start': start,\n",
    "            'end': end,\n",
    "            'duration': duration,\n",
    "            'confidence': round(avg_conf, 6),\n",
    "            'word_count': len(words),\n",
    "            'word_start': word_start,\n",
    "            'word_end': word_end\n",
    "        })\n",
    "\n",
    "    # Metadata\n",
    "    speakers = list(set(t['speaker'] for t in thought_dicts))\n",
    "    total_duration = word_data[-1].end if word_data else 0\n",
    "    metadata = {\n",
    "        'total_thoughts': len(thought_dicts),\n",
    "        'total_words': len(word_data),\n",
    "        'speakers': speakers,\n",
    "        'duration_ms': total_duration,\n",
    "        'duration_readable': str(timedelta(milliseconds=total_duration)),\n",
    "        'avg_confidence': round(sum(t['confidence'] for t in thought_dicts) / len(thought_dicts), 6) if thought_dicts else 0,\n",
    "    }\n",
    "\n",
    "    return {'thoughts': thought_dicts, 'metadata': metadata}\n",
    "\n",
    "# test\n",
    "# result = group_words_into_thoughts(transcript.words)\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acb0daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save thought segments and metadata to JSON\n",
    "\n",
    "def save_thought_segments(thoughts_result, output_path):\n",
    "    \"\"\"\n",
    "    Saves the thoughts and metadata to a JSON file.\n",
    "    \"\"\"\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(thoughts_result, f, indent=2)\n",
    "    print(f\"Saved thought segments and metadata to {output_path}\")\n",
    "\n",
    "# test\n",
    "# save_thought_segments(result, \"processed_thoughts.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1083a7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A word index map from word-level transcript\n",
    "def word_index_lookup(word_data):\n",
    "    \"\"\"\n",
    "    Builds a map from 1-based word index (as string) to word metadata.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        str(word['id']): {\n",
    "            'start': word['start'],\n",
    "            'end': word['end'],\n",
    "            'text': word['text'],\n",
    "            'speaker': word['speaker']\n",
    "        }\n",
    "        for word in word_data\n",
    "    }\n",
    "\n",
    "# Test:\n",
    "# with open(\"transcript.json\") as f:\n",
    "#     word_data = json.load(f)\n",
    "# word_index_map = word_index_lookup(word_data)\n",
    "# print(word_index_map['2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ead7e314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export VTT subtitles\n",
    "def export_vtt_subtitles(transcript, output_path: str, chars_per_caption: int = 30):\n",
    "    \"\"\"\n",
    "    Writes VTT subtitles to `output_path` using AssemblyAI's built-in exporter.\n",
    "    \"\"\"\n",
    "    vtt_text = transcript.export_subtitles_vtt(chars_per_caption=chars_per_caption)\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(vtt_text)\n",
    "    print(f\"Saved VTT subtitles to {output_path}\")\n",
    "\n",
    "# Test\n",
    "# export_vtt_subtitles(transcript, f\"subtitle_{video_id}.vtt\", chars_per_caption=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fd8d461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 09:50:26,215 INFO: HTTP Request: POST https://api.assemblyai.com/v2/upload \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:50:26,545 INFO: HTTP Request: POST https://api.assemblyai.com/v2/transcript \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:50:26,865 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:50:30,115 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:50:33,364 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:50:36,695 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:50:39,943 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:50:43,200 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:50:46,515 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:50:49,757 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:50:53,065 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:50:56,352 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:50:59,621 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:02,866 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:06,108 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:09,350 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:12,591 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:15,901 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:19,139 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:22,530 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:25,780 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:29,023 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:32,284 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:35,563 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:38,802 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:42,117 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:45,391 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:48,636 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:51,948 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:55,223 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:51:58,471 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:52:01,777 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:52:05,030 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:52:08,315 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 09:52:15,078 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved word-level transcript to transcript_3qHkcs3kG44_word_level.json\n",
      "Saved thought segments and metadata to processed_thoughts_3qHkcs3kG44.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 09:52:22,487 INFO: HTTP Request: GET https://api.assemblyai.com/v2/transcript/1302f387-8216-4696-8368-70f0ec746ba7/vtt?chars_per_caption=30 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved VTT subtitles to subtitle_3qHkcs3kG44.vtt\n",
      "Pipeline finished ✔\n"
     ]
    }
   ],
   "source": [
    "# Pipeline execution.\n",
    "youtube_url  = \"https://www.youtube.com/watch?v=3qHkcs3kG44\"\n",
    "video_id     = extract_youtube_video_id(youtube_url)\n",
    "audio_path   = download_youtube_audio(video_id)\n",
    "transcript   = transcribe_with_assemblyai(str(audio_path), return_transcript=True)\n",
    "\n",
    "save_word_level_transcript(transcript.words, f\"transcript_{video_id}_word_level.json\")\n",
    "thoughts_res = group_words_into_thoughts(transcript.words)\n",
    "save_thought_segments(thoughts_res, f\"processed_thoughts_{video_id}.json\")\n",
    "export_vtt_subtitles(transcript, f\"subtitle_{video_id}.vtt\")\n",
    "\n",
    "print(\"Pipeline finished ✔\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0fd2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "notes to myself:\n",
    "You've completed a major part of the pipeline. That's amazing. be curious.\n",
    "\n",
    "next steps:\n",
    "pass it to the LLM. (mention the encoding you've done, ans give you answer in the encoding thoughtID & wordID)\n",
    "when you get the respone. you need to decode the thoughtID and the wordID. You need the wordID to exactly cut the video from.\n",
    "smart move: don't actually build a video/audio cutting engine right now to cut the clips. but use a  music player that takes you to that specific moment.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c98b500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 717030, 'end': 717310, 'text': 'You', 'speaker': 'A'}\n"
     ]
    }
   ],
   "source": [
    "with open(f\"transcript_{video_id}_word_level.json\") as f:\n",
    "    word_data = json.load(f)\n",
    "word_index_map = word_index_lookup(word_data)\n",
    "print(word_index_map['2430'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ee84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 July 2025\n",
    "# LLM Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba8a6cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Processing chunks_3qHkcs3kG44/chunk_0.json ...🧠 Processing chunks_3qHkcs3kG44/chunk_1.json ...\n",
      "\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_10.json ...\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_11.json ...\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_12.json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:43:41,269 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 10:43:41,304 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 10:43:41,719 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 10:43:42,664 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 10:43:42,670 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_10.json, saved raw output -> results_3qHkcs3kG44/chunk_10_result_raw.txt\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_13.json ...\n",
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_11.json, saved raw output -> results_3qHkcs3kG44/chunk_11_result_raw.txt\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_14.json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:43:44,503 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 10:43:44,935 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_12.json, saved raw output -> results_3qHkcs3kG44/chunk_12_result_raw.txt\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_15.json ...\n",
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_13.json, saved raw output -> results_3qHkcs3kG44/chunk_13_result_raw.txt\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_16.json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:43:46,184 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 10:43:46,533 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_14.json, saved raw output -> results_3qHkcs3kG44/chunk_14_result_raw.txt\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_17.json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:43:47,034 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_0.json, saved raw output -> results_3qHkcs3kG44/chunk_0_result_raw.txt\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_18.json ...\n",
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_15.json, saved raw output -> results_3qHkcs3kG44/chunk_15_result_raw.txt\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_19.json ...\n",
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_16.json, saved raw output -> results_3qHkcs3kG44/chunk_16_result_raw.txt\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_2.json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:43:47,813 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 10:43:47,931 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 10:43:47,960 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_17.json, saved raw output -> results_3qHkcs3kG44/chunk_17_result_raw.txt\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_3.json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:43:48,061 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:43:48,062 INFO: Retrying request to /chat/completions in 8.192000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_1.json, saved raw output -> results_3qHkcs3kG44/chunk_1_result_raw.txt\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_4.json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:43:48,315 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:43:48,316 INFO: Retrying request to /chat/completions in 3.802000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_19.json, saved raw output -> results_3qHkcs3kG44/chunk_19_result_raw.txt\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_5.json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:43:49,121 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:43:49,125 INFO: Retrying request to /chat/completions in 4.822000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_18.json, saved raw output -> results_3qHkcs3kG44/chunk_18_result_raw.txt\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_6.json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:43:49,361 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:43:49,363 INFO: Retrying request to /chat/completions in 2.254000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_2.json, saved raw output -> results_3qHkcs3kG44/chunk_2_result_raw.txt\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_7.json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:43:50,608 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:43:50,610 INFO: Retrying request to /chat/completions in 7.595000 seconds\n",
      "2025-07-16 10:43:51,885 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:43:51,887 INFO: Retrying request to /chat/completions in 1.214000 seconds\n",
      "2025-07-16 10:43:52,383 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:43:52,385 INFO: Retrying request to /chat/completions in 2.262000 seconds\n",
      "2025-07-16 10:43:54,649 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:43:54,651 INFO: Retrying request to /chat/completions in 3.296000 seconds\n",
      "2025-07-16 10:43:54,906 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Rate limit hit. Retry 1 in 2s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:43:55,165 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 10:43:56,509 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:43:56,510 INFO: Retrying request to /chat/completions in 4.782000 seconds\n",
      "2025-07-16 10:43:57,657 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_6.json, saved raw output -> results_3qHkcs3kG44/chunk_6_result_raw.txt\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_8.json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:43:58,183 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:43:58,186 INFO: Retrying request to /chat/completions in 1.694000 seconds\n",
      "2025-07-16 10:43:58,521 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:43:58,523 INFO: Retrying request to /chat/completions in 6.540000 seconds\n",
      "2025-07-16 10:43:58,556 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Rate limit hit. Retry 1 in 2s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:44:00,134 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:44:00,136 INFO: Retrying request to /chat/completions in 0.282000 seconds\n",
      "2025-07-16 10:44:00,858 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:44:00,860 INFO: Retrying request to /chat/completions in 1.422000 seconds\n",
      "2025-07-16 10:44:01,035 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 10:44:01,603 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Rate limit hit. Retry 1 in 2s...\n",
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_8.json, saved raw output -> results_3qHkcs3kG44/chunk_8_result_raw.txt\n",
      "🧠 Processing chunks_3qHkcs3kG44/chunk_9.json ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:44:01,994 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:44:01,997 INFO: Retrying request to /chat/completions in 2.294000 seconds\n",
      "2025-07-16 10:44:02,866 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:44:02,869 INFO: Retrying request to /chat/completions in 2.620000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_4.json, saved raw output -> results_3qHkcs3kG44/chunk_4_result_raw.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:44:04,322 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:44:04,323 INFO: Retrying request to /chat/completions in 5.130000 seconds\n",
      "2025-07-16 10:44:04,577 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:44:04,580 INFO: Retrying request to /chat/completions in 0.276000 seconds\n",
      "2025-07-16 10:44:05,353 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Rate limit hit. Retry 1 in 2s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:44:05,718 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 10:44:05,731 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Rate limit hit. Retry 2 in 4s...\n",
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_9.json, saved raw output -> results_3qHkcs3kG44/chunk_9_result_raw.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:44:07,944 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:44:07,947 INFO: Retrying request to /chat/completions in 4.670000 seconds\n",
      "2025-07-16 10:44:09,700 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:44:09,702 INFO: Retrying request to /chat/completions in 3.496000 seconds\n",
      "2025-07-16 10:44:10,311 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_5.json, saved raw output -> results_3qHkcs3kG44/chunk_5_result_raw.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:44:12,881 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:44:12,883 INFO: Retrying request to /chat/completions in 4.526000 seconds\n",
      "2025-07-16 10:44:13,484 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Rate limit hit. Retry 2 in 4s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:44:17,891 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:44:17,893 INFO: Retrying request to /chat/completions in 0.212000 seconds\n",
      "2025-07-16 10:44:17,908 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-16 10:44:18,393 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-07-16 10:44:18,395 INFO: Retrying request to /chat/completions in 7.210000 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved result for chunks_3qHkcs3kG44/chunk_7.json -> results_3qHkcs3kG44/chunk_7_result.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 10:44:26,597 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Failed to parse JSON for chunks_3qHkcs3kG44/chunk_3.json, saved raw output -> results_3qHkcs3kG44/chunk_3_result_raw.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Configuration\n",
    "CHUNKS_FOLDER = \"chunks_3qHkcs3kG44\"  # Folder with chunk JSON files\n",
    "OUTPUT_FOLDER = \"results_3qHkcs3kG44\"  # Where to save outputs\n",
    "MAX_WORKERS = 5  # Number of parallel threads (tune based on your rate limit)\n",
    "MAX_RETRIES = 5\n",
    "RETRY_BASE_WAIT = 2  # seconds base for exponential backoff\n",
    "\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# Prompt template\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert at identifying motivational, philosophical, and inspirational moments from speech.\n",
    "\n",
    "Below is a list of thought segments from a YouTube interview, each with an ID, word start, and word end. The word start is the count number of the first word of that particular thought and the word end is the count number of the last word of that thought. Analyze them deeply and return a list of IDs that have the highest inspirational, philosophical, or viral potential.\n",
    "\n",
    "Ignore filler or generic phrases. Focus on unique insights, emotional resonance, or motivational power.\n",
    "\n",
    "Thoughts:\n",
    "{formatted_thoughts}\n",
    "\n",
    "Only return a JSON like this:\n",
    "{{ \"top_thought_ids\": [[\"t_0004\", 6, 20], [\"t_0035\", 303, 330], [\"t_0700\", 1235, 1535]] }}\n",
    "\n",
    "Reference:\n",
    "For thought ID: t_0004 the best moment is the sentence spoken from word 6 to 20. You need to give me the exact word start and word end of the best moment.\n",
    "\"\"\"\n",
    "\n",
    "def load_chunk(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    cleaned = [\n",
    "        {\n",
    "            \"id\": t[\"id\"],\n",
    "            \"word_start\": t[\"word_start\"],\n",
    "            \"word_end\": t[\"word_end\"],\n",
    "            \"text\": t[\"text\"]\n",
    "        }\n",
    "        for t in data[\"thoughts\"]\n",
    "    ]\n",
    "    formatted = \"\\n\\n\".join([\n",
    "        f\"ID: {t['id']}\\nStart: {t['word_start']}\\nEnd: {t['word_end']}\\nText: {t['text']}\"\n",
    "        for t in cleaned\n",
    "    ])\n",
    "    return formatted\n",
    "\n",
    "def call_openai_stream(prompt):\n",
    "    retries = 0\n",
    "    while retries <= MAX_RETRIES:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                stream=True,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You identify high-impact inspirational moments from transcripts.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.7,\n",
    "            )\n",
    "            full_output = \"\"\n",
    "            for chunk in response:\n",
    "                content = getattr(chunk.choices[0].delta, \"content\", \"\") or \"\"\n",
    "                full_output += content\n",
    "            return full_output\n",
    "        except Exception as e:\n",
    "            msg = str(e).lower()\n",
    "            if \"429\" in msg or \"rate limit\" in msg:\n",
    "                wait_time = RETRY_BASE_WAIT * (2 ** retries)\n",
    "                print(f\"⚠️ Rate limit hit. Retry {retries + 1} in {wait_time}s...\")\n",
    "                time.sleep(wait_time)\n",
    "                retries += 1\n",
    "            else:\n",
    "                print(f\"❌ OpenAI call failed: {e}\")\n",
    "                break\n",
    "    return None\n",
    "\n",
    "def process_chunk(chunk_path):\n",
    "    print(f\"🧠 Processing {chunk_path} ...\")\n",
    "    formatted_thoughts = load_chunk(chunk_path)\n",
    "    prompt = PROMPT_TEMPLATE.format(formatted_thoughts=formatted_thoughts)\n",
    "\n",
    "    result = call_openai_stream(prompt)\n",
    "    if result is None:\n",
    "        print(f\"⚠️ Failed to get response for {chunk_path}\")\n",
    "        return\n",
    "\n",
    "    # Try to parse JSON, else save raw\n",
    "    try:\n",
    "        parsed = json.loads(result)\n",
    "        out_path = os.path.join(OUTPUT_FOLDER, os.path.basename(chunk_path).replace(\".json\", \"_result.json\"))\n",
    "        with open(out_path, \"w\") as f:\n",
    "            json.dump(parsed, f, indent=2)\n",
    "        print(f\"✅ Saved result for {chunk_path} -> {out_path}\")\n",
    "    except Exception:\n",
    "        raw_out_path = os.path.join(OUTPUT_FOLDER, os.path.basename(chunk_path).replace(\".json\", \"_result_raw.txt\"))\n",
    "        with open(raw_out_path, \"w\") as f:\n",
    "            f.write(result)\n",
    "        print(f\"⚠️ Failed to parse JSON for {chunk_path}, saved raw output -> {raw_out_path}\")\n",
    "\n",
    "def main():\n",
    "    chunk_files = sorted([\n",
    "        os.path.join(CHUNKS_FOLDER, f)\n",
    "        for f in os.listdir(CHUNKS_FOLDER)\n",
    "        if f.endswith(\".json\")\n",
    "    ])\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        executor.map(process_chunk, chunk_files)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd6bac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
